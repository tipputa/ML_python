{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5章 誤差逆伝播法\n",
    "\n",
    "180226, pp123-163\n",
    "\n",
    "目次\n",
    "\n",
    "1. 計算グラフ\n",
    "2. 連鎖律\n",
    "3. 逆伝播\n",
    "4. 単純なレイヤの実装\n",
    "5. 活性化関数レイヤの実装\n",
    "6. Affine/Softmaxレイヤの実装\n",
    "7. 誤差逆伝播法の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "4章では、ニューラルネットワークの重みパラメータの勾配（重みパラメータに関する損失関数の勾配）は、数値微分によって求めた。数値微分はシンプルで実装は簡単だが、計算に時間がかかる。本章では、重みパラメー タの勾配の計算を効率良く行う手法である「誤差逆伝播法」について学ぶ。\n",
    "\n",
    "誤差逆伝播法を正しく理解する方法\n",
    "1. 数式; 厳密で簡潔になるが、本質的なことを見逃したり数式の羅列にとどまることがある。\n",
    "2. 計算グラフ; 視覚的に説明し、「なるほど!」と納得できるため、本章では計算グラフの説明を行う。\n",
    "\n",
    "重要：　誤差逆伝播法の概念、レイヤによる実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 計算グラフ\n",
    "計算の過程をグラフによって表現。順伝播（左→右）と逆伝播（右→左）。**逆伝播によって微分を効率よく計算**できる。\n",
    "\n",
    "## 2. 連鎖律\n",
    "ある関数が合成関数で表される場合、その合成関数の微分は、合成関数を構成するそれぞれの関数の微分の積によって表すことができる。\n",
    "\n",
    "## 3. 逆伝播\n",
    "加算ノード： そのまま伝播　（インプットを保存する必要なし）。 z = x + y の偏微分は共に1なため。\n",
    "\n",
    "乗算ノード： ひっくり返した値を乗算し伝播（インプットを保持）　z = xy の偏微分はひっくり返るため。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# この後必要になるライブラリを一括でDL\n",
    "import numpy as np\n",
    "import sys, os, time\n",
    "from collections import OrderedDict # 順序付きDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.pardir) # load_mnistするために親ディレクトリを追加。必要に応じて変更 or dataset.mnistを別途import\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## これまでの章で使った関数のインポート。 \n",
    "## 本来は下記の2つのインポート文でも良いが、参照しやすいように記載\n",
    "# from common.layers import *\n",
    "# from common.gradient import numerical_gradient\n",
    "\n",
    "# 3.2 章\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "# 4.4章より, 微分を使った勾配算出用 \n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 値を元に戻す\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# 3章より\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # オーバーフロー対策\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "# 4章より\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 単純なレイヤの実装　（乗算と加算レイヤ）\n",
    "実際にニューラルネットワークを構築するときに、それぞれのレイヤを組み合わせるだけで簡単に計算できるようになる。（ここではデモのみ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乗算レイヤーの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    # 順伝播\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    # 逆伝播\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乗算レイヤを実施に使ってみる。2つのリンゴを購入して消費税1.1が掛かった場合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 220\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dTax: 200\n",
      "dapple * apple = 220\n",
      "dapple_num * apple_num = 220\n",
      "dTax * tax = 220\n"
     ]
    }
   ],
   "source": [
    "# 100円のリンゴ2つを購入し、1.1倍する。\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dTax:\", dtax)\n",
    "\n",
    "print(\"dapple * apple = \" + ('%0.0f' % (dapple * apple)) )\n",
    "print(\"dapple_num * apple_num = \" + ('%0.0f' % (dapple_num * apple_num)))\n",
    "print(\"dTax * tax = \" + ('%0.0f' % (dtax * tax)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "加算レイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加算レイヤを乗算レイヤと組み合わせて実際に使ってみる。リンゴ2個とみかん3個を購入し、消費税1.1が掛かった場合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 活性化関数レイヤの実装\n",
    "ReLU と Sigmoidの実装。Sigmoidの逆伝播は143-146参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0 # x <= 0で0を出力\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0 # x <= 0で0を出力\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Affine/Softmaxレイヤの実装\n",
    "入力である行列に重さを乗算し、バイアスを加える。(Y=XW+B)\n",
    "\n",
    "Affine: 行列の積の計算を、幾何学の分野では「アフィン変換」という。\n",
    "\n",
    "\n",
    "入力（X）への逆伝播： ∂L/∂X = ∂L/∂Y ・ W.T\n",
    "\n",
    "重み（W）への逆伝播：∂L/∂W = X.T ・ ∂L/∂Y\n",
    "\n",
    "バイアス（B）への逆伝播：∂L/∂B = ∂L/∂Yの列方向に対する和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 重み・バイアスパラメータの微分\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # テンソル対応\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 入力データの形状に戻す（テンソル対応）\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここではSoftmaxと交差エントロピー誤差をまとめて実装している。そうすることで、逆伝播の値がy-tという非常にキレイな値となる。\n",
    "\n",
    "Softmaxには交差エントロピー誤差を、恒等関数の場合は二乗和誤差を損失関数として求めると、キレイな結果となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Softmaxと交差 エントロピー誤差をまとめて実装。\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmaxの出力\n",
    "        self.t = None # 教師データ\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 教師データがone-hot-vectorの場合\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**具体例1**： Softmaxレイヤの出力（0.3, 0.2, 0.5）で教師ラベルが（0, 1, 0）の場合\n",
    "\n",
    "正解の確率が20%しかない。y-tが（0.3, -0.8, 0.5）と大きい値となり、大きな誤差が逆伝播される。\n",
    "\n",
    "**具体例2**： Softmaxレイヤの出力（0.01, 0.99, 0）で教師ラベルが（0, 1, 0）の場合\n",
    "\n",
    "正解の確率が99%。y-tが（0.01, -0.01, 0）となり、小さい誤差が逆伝播される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 誤差逆伝播法の実装\n",
    "これまでのレイヤを組み合わせることで、まるでレゴブロックのようにニューラルネットワークを実装することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 実行速度の差を確認する用\n",
    "import time\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "        self.lap_start = self.start\n",
    "        self.lap_list = []\n",
    "\n",
    "    def lap_show (self):\n",
    "        now = time.time()\n",
    "        lap = now - self.lap_start\n",
    "        self.lap_list.append(lap)\n",
    "        self.lap_start = now\n",
    "        print(\"lap \" + str(len(self.lap_list)) + ((\": %0.7f sec\") %lap) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "実行速度 lap1: 数値微分、lap2: 誤差逆伝播法\n",
      "lap 1: 17.7218502 sec\n",
      "lap 2: 0.0016599 sec\n",
      "W1:4.19503097552e-10\n",
      "b2:1.39655118951e-07\n",
      "W2:5.16147253303e-09\n",
      "b1:2.7570582356e-09\n",
      "誤差逆伝播法の方が10676.6倍早い\n"
     ]
    }
   ],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "timer = Timer()\n",
    "print(\"実行速度 lap1: 数値微分、lap2: 誤差逆伝播法\")\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch) # 数値微分\n",
    "timer.lap_show()\n",
    "\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "timer.lap_show()\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))\n",
    "\n",
    "print((\"誤差逆伝播法の方が%0.1f倍早い\" % (timer.lap_list[0] / timer.lap_list[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応ここで何が起きているのか確認（時間があれば）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:(60000, 784)\n",
      "t_train.shape:(60000, 10)\n",
      "x_train[0]の画像。28×28 = 784\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOX4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e8af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"x_train.shape:\" + str(x_train.shape))\n",
    "print(\"t_train.shape:\" + str(t_train.shape))\n",
    "print(\"x_train[0]の画像。28×28 = 784\")\n",
    "\n",
    "# 画像の表示\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "some_digit = x_train[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch: (3, 784)\n",
      "W1: (784, 50)\n",
      "b1: (50,)\n",
      "W2: (50, 10)\n",
      "b2: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_batch: \" + str(x_batch.shape))\n",
    "print(\"W1: \" + str(network.params['W1'].shape))\n",
    "print(\"b1: \" + str(network.params['b1'].shape))\n",
    "print(\"W2: \" + str(network.params['W2'].shape))\n",
    "print(\"b2: \" + str(network.params['b2'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch: (3, 784)\n",
      "Affine1の結果: X (3,784) * W (784, 50) + b1(50,) = (3, 50)\n",
      "After affine1: (3, 50)\n",
      "[-0.03346961 -0.02209822  0.09428647  0.07258174 -0.00075832  0.04128724\n",
      "  0.01685031  0.04622215 -0.09349863  0.16950605  0.21224032 -0.04984727\n",
      " -0.07236086  0.03207296  0.03925295 -0.02701086  0.07330976 -0.14762438\n",
      " -0.03713037 -0.00277914 -0.08626437  0.04495235  0.04345102 -0.07364867\n",
      "  0.0255347   0.11300004  0.01206745 -0.01550124  0.12050815 -0.06227472\n",
      "  0.0123423   0.12186568  0.04213566 -0.13564951 -0.16607256  0.04745166\n",
      " -0.07513735  0.02154409 -0.08790411  0.01461395 -0.03221075  0.02541651\n",
      " -0.07729277 -0.05064019  0.04622644  0.00264495 -0.14710056  0.02368563\n",
      " -0.0868902  -0.12672689]\n",
      "\n",
      "ReLU1の結果： (3, 50)の中でx<0を0に置換\n",
      "After ReLU: (3, 50)\n",
      "[ 0.          0.          0.09428647  0.07258174  0.          0.04128724\n",
      "  0.01685031  0.04622215  0.          0.16950605  0.21224032  0.          0.\n",
      "  0.03207296  0.03925295  0.          0.07330976  0.          0.          0.\n",
      "  0.          0.04495235  0.04345102  0.          0.0255347   0.11300004\n",
      "  0.01206745  0.          0.12050815  0.          0.0123423   0.12186568\n",
      "  0.04213566  0.          0.          0.04745166  0.          0.02154409\n",
      "  0.          0.01461395  0.          0.02541651  0.          0.\n",
      "  0.04622644  0.00264495  0.          0.02368563  0.          0.        ]\n",
      "\n",
      "Affine2の結果: X (3,50) * W2 (50, 10) + b2(10,) = (3, 10)\n",
      "After affine2: (3, 10)\n",
      "[  7.08849603e-03  -9.76074914e-04  -9.62285676e-05  -1.26580801e-03\n",
      "   5.50477130e-03   4.39597581e-03   6.19621623e-03  -3.79605637e-04\n",
      "   3.50362238e-03  -2.93540531e-03]\n",
      "\n",
      "softmax, 確率に変換\n",
      "[ 0.10049914  0.09969192  0.09977967  0.09966304  0.10034011  0.10022891\n",
      "  0.10040951  0.0997514   0.10013951  0.09949678]\n",
      "1つのサンプルにつき総和は1.0\n",
      "\n",
      "交差エントロピー誤差：2.30162797276\n"
     ]
    }
   ],
   "source": [
    "print(\"x_batch: \" + str(x_batch.shape))\n",
    "print(\"Affine1の結果: X (3,784) * W (784, 50) + b1(50,) = (3, 50)\")\n",
    "res1 = network.layers['Affine1'].forward(x_batch)\n",
    "print(\"After affine1: \" + str(res1.shape))\n",
    "print(res1[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"ReLU1の結果： (3, 50)の中でx<0を0に置換\")\n",
    "res2 = network.layers['Relu1'].forward(res1)\n",
    "print(\"After ReLU: \" + str(res2.shape))\n",
    "print(res2[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"Affine2の結果: X (3,50) * W2 (50, 10) + b2(10,) = (3, 10)\")\n",
    "res3 = network.layers['Affine2'].forward(res2)\n",
    "print(\"After affine2: \" + str(res3.shape))\n",
    "print(res3[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"softmax, 確率に変換\")\n",
    "res4 = softmax(res3)\n",
    "print(res4[0])\n",
    "print(\"1つのサンプルにつき総和は\" + str(np.sum(res4[0])))\n",
    "print(\"\")\n",
    "\n",
    "res5 = cross_entropy_error(res4, t_batch)\n",
    "print(\"交差エントロピー誤差：\" + str(res5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記が1セット。勾配を求めるために数値微分を行う場合、各パラメーターの各値につき±hの交差エントロピー誤差を算出する必要がある。\n",
    "\n",
    "(W1(784 * 50) + b1(50) + W2(50 * 10) + b2(10))  * 2 = 79520回上記の計算を繰り返して、やっと1回全てのパラメータを更新できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79520"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(784*50+50+50*10+10)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方、誤差逆伝播法の場合、逆伝播を行っていくだけ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "まず一度1セット流して値をセット\n",
      "loss 2.30162797276\n",
      "\n",
      "逆伝播, softmax & cross_entropy_error, 計算内容：y-t\n",
      "(3, 10)\n",
      "[ 0.03349971  0.03323064  0.03325989  0.03322101  0.0334467  -0.2999237\n",
      "  0.03346984  0.03325047  0.03337984  0.03316559]\n",
      "\n",
      "逆伝播, Affine2, 計算内容： 2回内積, 1回総和\n",
      "(3, 50)\n",
      "[  2.19227530e-03   5.24925815e-03  -1.74718373e-04   1.04108396e-05\n",
      "  -2.00154219e-03  -1.46907545e-03  -6.96940644e-03   4.42597134e-03\n",
      "  -7.53770142e-03  -2.16003111e-03  -7.72511713e-04  -2.17785675e-03\n",
      "   1.46818527e-03  -4.99829772e-04   1.77953608e-03  -6.64849473e-03\n",
      "   2.57168171e-03  -9.56849227e-04  -8.36352133e-04   1.76210897e-03\n",
      "  -5.73687636e-03  -9.98545451e-06   5.26668354e-03   6.70992290e-03\n",
      "   5.34164041e-04  -3.20545869e-03  -2.71229881e-03  -1.16327486e-03\n",
      "   5.76032200e-03  -2.42314604e-03   8.07136820e-04  -5.44532344e-03\n",
      "  -6.32206901e-05   4.27886241e-04  -8.55563056e-04  -6.87758454e-03\n",
      "  -4.25330011e-03   2.35374108e-03   8.77283161e-04   2.29986832e-03\n",
      "  -1.61236361e-03  -3.27186930e-03   1.33737983e-03  -3.24994345e-03\n",
      "   1.10590490e-03   2.62768405e-03  -2.33449996e-03  -4.26671798e-03\n",
      "   1.33316686e-03  -3.04352663e-03]\n",
      "\n",
      "逆伝播, ReLU1, 計算内容： x<0の判定、0の代入\n",
      "(3, 50)\n",
      "[  0.00000000e+00   0.00000000e+00  -1.74718373e-04   1.04108396e-05\n",
      "   0.00000000e+00  -1.46907545e-03  -6.96940644e-03   4.42597134e-03\n",
      "   0.00000000e+00  -2.16003111e-03  -7.72511713e-04   0.00000000e+00\n",
      "   0.00000000e+00  -4.99829772e-04   1.77953608e-03   0.00000000e+00\n",
      "   2.57168171e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -9.98545451e-06   5.26668354e-03   0.00000000e+00\n",
      "   5.34164041e-04  -3.20545869e-03  -2.71229881e-03   0.00000000e+00\n",
      "   5.76032200e-03   0.00000000e+00   8.07136820e-04  -5.44532344e-03\n",
      "  -6.32206901e-05   0.00000000e+00   0.00000000e+00  -6.87758454e-03\n",
      "   0.00000000e+00   2.35374108e-03   0.00000000e+00   2.29986832e-03\n",
      "   0.00000000e+00  -3.27186930e-03   0.00000000e+00   0.00000000e+00\n",
      "   1.10590490e-03   2.62768405e-03   0.00000000e+00  -4.26671798e-03\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "\n",
      "逆伝播, Affine2, 計算内容：2回内積, 1回総和\n",
      "(3, 784)\n",
      "\n",
      "W1, W2, b1, b2もこれで計算されている\n",
      "W1(784, 50)\n",
      "W2(50, 10)\n",
      "b1(50,)\n",
      "b2(10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"まず一度1セット流して値をセット\")\n",
    "print(\"loss \" + str(network.loss(x_batch, t_batch)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"逆伝播, softmax & cross_entropy_error, 計算内容：y-t\")\n",
    "dout = 1\n",
    "dout = network.lastLayer.backward(dout)\n",
    "print(dout.shape)\n",
    "print(dout[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"逆伝播, Affine2, 計算内容： 2回内積, 1回総和\")\n",
    "dout = network.layers['Affine2'].backward(dout)\n",
    "print(dout.shape)\n",
    "print(dout[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"逆伝播, ReLU1, 計算内容： x<0の判定、0の代入\")\n",
    "dout = network.layers['Relu1'].backward(dout)\n",
    "print(dout.shape)\n",
    "print(dout[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"逆伝播, Affine2, 計算内容：2回内積, 1回総和\")\n",
    "dout = network.layers['Affine1'].backward(dout)\n",
    "print(dout.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(\"W1, W2, b1, b2もこれで計算されている\")\n",
    "print(\"W1\" + str(network.layers['Affine1'].dW.shape))\n",
    "print(\"W2\" + str(network.layers['Affine2'].dW.shape))\n",
    "print(\"b1\" + str(network.layers['Affine1'].db.shape))\n",
    "print(\"b2\" + str(network.layers['Affine2'].db.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほぼほぼ同じ精度を出しているのに、計算回数は数万倍ぐらい違う。計算が1万倍ぐらい早くなるのも当然である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、一応実装結果を確認してみる。（4章と同一であるため説明省略）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lap 1: 1.3485000 sec\n",
      "train acc, test acc | 0.0644666666667, 0.059\n",
      "lap 2: 4.4882171 sec\n",
      "train acc, test acc | 0.9025, 0.9047\n",
      "lap 3: 3.3373680 sec\n",
      "train acc, test acc | 0.9201, 0.9223\n",
      "lap 4: 3.1633780 sec\n",
      "train acc, test acc | 0.937366666667, 0.9383\n",
      "lap 5: 3.1721389 sec\n",
      "train acc, test acc | 0.947483333333, 0.9481\n",
      "lap 6: 2.7860980 sec\n",
      "train acc, test acc | 0.951683333333, 0.9496\n",
      "lap 7: 3.2809110 sec\n",
      "train acc, test acc | 0.9584, 0.9569\n",
      "lap 8: 2.4228640 sec\n",
      "train acc, test acc | 0.963266666667, 0.9595\n",
      "lap 9: 3.1045799 sec\n",
      "train acc, test acc | 0.964533333333, 0.9613\n",
      "lap 10: 3.7780511 sec\n",
      "train acc, test acc | 0.969366666667, 0.9641\n",
      "lap 11: 3.4093261 sec\n",
      "train acc, test acc | 0.971466666667, 0.9659\n",
      "lap 12: 2.6490018 sec\n",
      "train acc, test acc | 0.97265, 0.9671\n",
      "lap 13: 3.0520132 sec\n",
      "train acc, test acc | 0.9749, 0.9694\n",
      "lap 14: 3.1590970 sec\n",
      "train acc, test acc | 0.97505, 0.968\n",
      "lap 15: 2.7254748 sec\n",
      "train acc, test acc | 0.977216666667, 0.9698\n",
      "lap 16: 3.1717241 sec\n",
      "train acc, test acc | 0.978683333333, 0.9698\n",
      "lap 17: 2.9946101 sec\n",
      "train acc, test acc | 0.979233333333, 0.971\n"
     ]
    }
   ],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "timer = Timer()\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        timer.lap_show()\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQURE2lAwiIhIG/8fwaZJ+8614N8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11202b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
